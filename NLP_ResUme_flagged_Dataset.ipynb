{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1sLwe56OVHBBCG1UKqFpQSZ_Jz1P4InVb",
      "authorship_tag": "ABX9TyMMZC+BF3HRgn97ibR4VKKY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nsrawat009/Credit-card-defaulters-Analysis/blob/main/NLP_ResUme_flagged_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1qwWzYLCuYOW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "df=pd.read_csv(r'/content/drive/MyDrive/Datasets/Sheet_2.csv',encoding='latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "I43SNEWuvFsI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "jaH0_ZMCyk56",
        "outputId": "0798353f-4b05-418f-c48d-8c4e1affd891"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      resume_id        class  \\\n",
              "0      resume_1  not_flagged   \n",
              "1      resume_2  not_flagged   \n",
              "2      resume_3  not_flagged   \n",
              "3      resume_4  not_flagged   \n",
              "4      resume_5      flagged   \n",
              "..          ...          ...   \n",
              "120  resume_121  not_flagged   \n",
              "121  resume_122  not_flagged   \n",
              "122  resume_123  not_flagged   \n",
              "123  resume_124      flagged   \n",
              "124  resume_125  not_flagged   \n",
              "\n",
              "                                           resume_text  \\\n",
              "0    \\rCustomer Service Supervisor/Tier - Isabella ...   \n",
              "1    \\rEngineer / Scientist - IBM Microelectronics ...   \n",
              "2    \\rLTS Software Engineer Computational Lithogra...   \n",
              "3     TUTOR\\rWilliston VT - Email me on Indeed: ind...   \n",
              "4    \\rIndependent Consultant - Self-employed\\rBurl...   \n",
              "..                                                 ...   \n",
              "120  \\rBrattleboro VT - Email me on Indeed: indeed....   \n",
              "121  \\rResearch and Teaching Assistant - University...   \n",
              "122  \\rMedical Coder - Highly Skilled - Entry Level...   \n",
              "123  \\rWaterbury VT - Email me on Indeed: indeed.co...   \n",
              "124  \\rResearch and Development Scientist - Burling...   \n",
              "\n",
              "                                          cleaned_text  \\\n",
              "0    customer service isabella catalog company sout...   \n",
              "1    engineer scientist ibm microelectronics divisi...   \n",
              "2    lts software engineer computational lithograph...   \n",
              "3    tutor williston vt email me on work experience...   \n",
              "4    independent consultant burlington vt email me ...   \n",
              "..                                                 ...   \n",
              "120  brattleboro vt email me on skilled presenter t...   \n",
              "121  research and teaching assistant university of ...   \n",
              "122  medical coder highly skilled entry level sudbu...   \n",
              "123  waterbury vt email me on willing to anywhere a...   \n",
              "124  research and development scientist burlington ...   \n",
              "\n",
              "                                       lemmatized_text  \n",
              "0    customer service isabella catalog company sout...  \n",
              "1    engineer scientist ibm microelectronics divisi...  \n",
              "2    lts software engineer computational lithograph...  \n",
              "3    tutor williston vt email me on work experience...  \n",
              "4    independent consultant burlington vt email me ...  \n",
              "..                                                 ...  \n",
              "120  brattleboro vt email me on skilled presenter t...  \n",
              "121  research and teaching assistant university of ...  \n",
              "122  medical coder highly skilled entry level sudbu...  \n",
              "123  waterbury vt email me on willing to anywhere a...  \n",
              "124  research and development scientist burlington ...  \n",
              "\n",
              "[125 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-679ed040-0261-4949-ae03-acdd188a6ae1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resume_id</th>\n",
              "      <th>class</th>\n",
              "      <th>resume_text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>lemmatized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>resume_1</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>\\rCustomer Service Supervisor/Tier - Isabella ...</td>\n",
              "      <td>customer service isabella catalog company sout...</td>\n",
              "      <td>customer service isabella catalog company sout...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>resume_2</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>\\rEngineer / Scientist - IBM Microelectronics ...</td>\n",
              "      <td>engineer scientist ibm microelectronics divisi...</td>\n",
              "      <td>engineer scientist ibm microelectronics divisi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>resume_3</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>\\rLTS Software Engineer Computational Lithogra...</td>\n",
              "      <td>lts software engineer computational lithograph...</td>\n",
              "      <td>lts software engineer computational lithograph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>resume_4</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>TUTOR\\rWilliston VT - Email me on Indeed: ind...</td>\n",
              "      <td>tutor williston vt email me on work experience...</td>\n",
              "      <td>tutor williston vt email me on work experience...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>resume_5</td>\n",
              "      <td>flagged</td>\n",
              "      <td>\\rIndependent Consultant - Self-employed\\rBurl...</td>\n",
              "      <td>independent consultant burlington vt email me ...</td>\n",
              "      <td>independent consultant burlington vt email me ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>resume_121</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>\\rBrattleboro VT - Email me on Indeed: indeed....</td>\n",
              "      <td>brattleboro vt email me on skilled presenter t...</td>\n",
              "      <td>brattleboro vt email me on skilled presenter t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>resume_122</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>\\rResearch and Teaching Assistant - University...</td>\n",
              "      <td>research and teaching assistant university of ...</td>\n",
              "      <td>research and teaching assistant university of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>resume_123</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>\\rMedical Coder - Highly Skilled - Entry Level...</td>\n",
              "      <td>medical coder highly skilled entry level sudbu...</td>\n",
              "      <td>medical coder highly skilled entry level sudbu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>resume_124</td>\n",
              "      <td>flagged</td>\n",
              "      <td>\\rWaterbury VT - Email me on Indeed: indeed.co...</td>\n",
              "      <td>waterbury vt email me on willing to anywhere a...</td>\n",
              "      <td>waterbury vt email me on willing to anywhere a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>resume_125</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>\\rResearch and Development Scientist - Burling...</td>\n",
              "      <td>research and development scientist burlington ...</td>\n",
              "      <td>research and development scientist burlington ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>125 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-679ed040-0261-4949-ae03-acdd188a6ae1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-679ed040-0261-4949-ae03-acdd188a6ae1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-679ed040-0261-4949-ae03-acdd188a6ae1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f3b929f4-4252-4273-b4a7-fb36f03c57df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3b929f4-4252-4273-b4a7-fb36f03c57df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f3b929f4-4252-4273-b4a7-fb36f03c57df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5e2f1bb9-be9b-4915-acab-5641e35052d2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5e2f1bb9-be9b-4915-acab-5641e35052d2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTy_ctoe7CIZ",
        "outputId": "57ed4735-6968-4928-bdb9-a9a92e3f3f8b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "not_flagged    92\n",
              "flagged        33\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Define functions for text cleaning\n",
        "def clean_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters and digits\n",
        "    text = ' '.join([word for word in text.split() if word.isalpha()])\n",
        "    return text\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# Apply text cleaning and lemmatization\n",
        "df['cleaned_text'] = df['resume_text'].apply(clean_text)\n",
        "df['lemmatized_text'] = df['cleaned_text'].apply(lemmatize_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMs4Jo5fvGNH",
        "outputId": "68e8a903-3fb5-4ea9-a812-a64f68e3533a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import nltk\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "# from sklearn.pipeline import make_pipeline\n",
        "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "# from nltk.corpus import stopwords\n",
        "# from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "# # Download NLTK resources\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('wordnet')\n",
        "\n",
        "# # Load the dataset\n",
        "# df = pd.read_csv(\"your_resume_dataset.csv\")\n",
        "\n",
        "# # Text cleaning and lemmatization functions\n",
        "# def clean_text(text):\n",
        "#     text = text.lower()\n",
        "#     text = ' '.join([word for word in text.split() if word.isalpha()])\n",
        "#     return text\n",
        "\n",
        "# def lemmatize_text(text):\n",
        "#     lemmatizer = WordNetLemmatizer()\n",
        "#     tokens = nltk.word_tokenize(text)\n",
        "#     lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "#     return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# # Apply text cleaning and lemmatization\n",
        "# df['cleaned_text'] = df['text'].apply(clean_text)\n",
        "# df['lemmatized_text'] = df['cleaned_text'].apply(lemmatize_text)\n",
        "\n",
        "# # Train-test split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(df['lemmatized_text'], df['flagged'], test_size=0.2, random_state=42)\n",
        "\n",
        "# # Apply SMOTE for oversampling\n",
        "# smote = SMOTE(random_state=42)\n",
        "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train.values.reshape(-1, 1), y_train)\n",
        "\n",
        "# X_train_resampled = X_train_resampled.flatten()\n",
        "\n",
        "# # Build a pipeline with TF-IDF Vectorizer and Multinomial Naive Bayes\n",
        "# model = make_pipeline(TfidfVectorizer(stop_words=stopwords.words('english')), MultinomialNB())\n",
        "\n",
        "# # Train the model on the resampled data\n",
        "# model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# # Evaluate the model\n",
        "# y_pred = model.predict(X_test)\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "# classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# print(f\"Accuracy: {accuracy}\")\n",
        "# print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "# print(f\"Classification Report:\\n{classification_rep}\")\n"
      ],
      "metadata": {
        "id": "L4w_9aG576vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ">>> import nltk\n",
        ">>> nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FydouC1WvGgp",
        "outputId": "570539dc-1314-4952-9331-05d614e82070"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['lemmatized_text'], df['class'], test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "49tT_P_hxPOc"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a pipeline with TF-IDF Vectorizer and Multinomial Naive Bayes\n",
        "model = make_pipeline(TfidfVectorizer(stop_words=stopwords.words('english')), MultinomialNB())\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "Fdki-jfFxPrt"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "as2I0Nvh8dyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{classification_rep}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5A7w20ZywP3",
        "outputId": "92a8034a-c37c-4dcf-9902-8d20c1c7b431"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6\n",
            "Confusion Matrix:\n",
            "[[ 0 10]\n",
            " [ 0 15]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     flagged       0.00      0.00      0.00        10\n",
            " not_flagged       0.60      1.00      0.75        15\n",
            "\n",
            "    accuracy                           0.60        25\n",
            "   macro avg       0.30      0.50      0.37        25\n",
            "weighted avg       0.36      0.60      0.45        25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MLNfu2eD0MOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a new resume text\n",
        "new_resume = \"Your new resume text goes here.fddfdddddddddd\"\n",
        "\n",
        "# Clean and lemmatize the new resume text\n",
        "cleaned_resume = lemmatize_text(clean_text(new_resume))\n",
        "\n",
        "# Make predictions\n",
        "prediction = model.predict([cleaned_resume])\n",
        "\n",
        "print(f\"The model predicts: {prediction[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3ONkRzwyxBy",
        "outputId": "dc1a63fc-a2ae-48cb-fcbd-0fd335963f6f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model predicts: not_flagged\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#improve model performance, perform hyperparameter optimization"
      ],
      "metadata": {
        "id": "S3obMUOfyxIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Hyperparameter optimization using GridSearchCV\n",
        "param_grid = {\n",
        "    'tfidfvectorizer__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidfvectorizer__max_df': [0.7, 0.8, 0.9],\n",
        "    'multinomialnb__alpha': [0.1, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "# Create a pipeline\n",
        "pipeline = make_pipeline(TfidfVectorizer(stop_words=stopwords.words('english')), MultinomialNB())\n",
        "\n",
        "# GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Evaluate the model with best parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{classification_rep}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTzINHAR4s0a",
        "outputId": "9842d928-6ec2-414f-a197-f4e635aa30ee"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'multinomialnb__alpha': 0.1, 'tfidfvectorizer__max_df': 0.7, 'tfidfvectorizer__ngram_range': (1, 1)}\n",
            "Accuracy: 0.6\n",
            "Confusion Matrix:\n",
            "[[ 0 10]\n",
            " [ 0 15]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     flagged       0.00      0.00      0.00        10\n",
            " not_flagged       0.60      1.00      0.75        15\n",
            "\n",
            "    accuracy                           0.60        25\n",
            "   macro avg       0.30      0.50      0.37        25\n",
            "weighted avg       0.36      0.60      0.45        25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load the dataset\n",
        "df=pd.read_csv(r'/content/drive/MyDrive/Datasets/Sheet_2.csv',encoding='latin-1')\n",
        "\n",
        "# Text cleaning and lemmatization functions\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = ' '.join([word for word in text.split() if word.isalpha()])\n",
        "    return text\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# Apply text cleaning and lemmatization\n",
        "df['cleaned_text'] = df['resume_text'].apply(clean_text)\n",
        "df['lemmatized_text'] = df['cleaned_text'].apply(lemmatize_text)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['lemmatized_text'], df['flagged'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE for oversampling\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train.values.reshape(-1, 1), y_train)\n",
        "\n",
        "X_train_resampled = X_train_resampled.flatten()\n",
        "\n",
        "# Build a pipeline with TF-IDF Vectorizer and Multinomial Naive Bayes\n",
        "model = make_pipeline(TfidfVectorizer(stop_words=stopwords.words('english')), MultinomialNB())\n",
        "\n",
        "# Train the model on the resampled data\n",
        "model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{classification_rep}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "bQ2xBeSlyxNL",
        "outputId": "38e29d71-c028-4074-da4a-fac3e2ccc66a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'flagged'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-1ecf62b3a3e1>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Train-test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lemmatized_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flagged'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Apply SMOTE for oversampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'flagged'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q14YC0HPA8jE",
        "outputId": "df4c8bc7-94b5-4201-a8be-3e673bb435ef"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "hiSzT7BkB7kB",
        "outputId": "03f6ebda-fd67-4cc8-cd76-79cb9f5f3d92"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      resume_id        class  \\\n",
              "0      resume_1  not_flagged   \n",
              "1      resume_2  not_flagged   \n",
              "2      resume_3  not_flagged   \n",
              "3      resume_4  not_flagged   \n",
              "4      resume_5      flagged   \n",
              "..          ...          ...   \n",
              "120  resume_121  not_flagged   \n",
              "121  resume_122  not_flagged   \n",
              "122  resume_123  not_flagged   \n",
              "123  resume_124      flagged   \n",
              "124  resume_125  not_flagged   \n",
              "\n",
              "                                           resume_text  \\\n",
              "0    \\rCustomer Service Supervisor/Tier - Isabella ...   \n",
              "1    \\rEngineer / Scientist - IBM Microelectronics ...   \n",
              "2    \\rLTS Software Engineer Computational Lithogra...   \n",
              "3     TUTOR\\rWilliston VT - Email me on Indeed: ind...   \n",
              "4    \\rIndependent Consultant - Self-employed\\rBurl...   \n",
              "..                                                 ...   \n",
              "120  \\rBrattleboro VT - Email me on Indeed: indeed....   \n",
              "121  \\rResearch and Teaching Assistant - University...   \n",
              "122  \\rMedical Coder - Highly Skilled - Entry Level...   \n",
              "123  \\rWaterbury VT - Email me on Indeed: indeed.co...   \n",
              "124  \\rResearch and Development Scientist - Burling...   \n",
              "\n",
              "                                          cleaned_text  \\\n",
              "0    customer service isabella catalog company sout...   \n",
              "1    engineer scientist ibm microelectronics divisi...   \n",
              "2    lts software engineer computational lithograph...   \n",
              "3    tutor williston vt email me on work experience...   \n",
              "4    independent consultant burlington vt email me ...   \n",
              "..                                                 ...   \n",
              "120  brattleboro vt email me on skilled presenter t...   \n",
              "121  research and teaching assistant university of ...   \n",
              "122  medical coder highly skilled entry level sudbu...   \n",
              "123  waterbury vt email me on willing to anywhere a...   \n",
              "124  research and development scientist burlington ...   \n",
              "\n",
              "                                       lemmatized_text  \n",
              "0    customer service isabella catalog company sout...  \n",
              "1    engineer scientist ibm microelectronics divisi...  \n",
              "2    lts software engineer computational lithograph...  \n",
              "3    tutor williston vt email me on work experience...  \n",
              "4    independent consultant burlington vt email me ...  \n",
              "..                                                 ...  \n",
              "120  brattleboro vt email me on skilled presenter t...  \n",
              "121  research and teaching assistant university of ...  \n",
              "122  medical coder highly skilled entry level sudbu...  \n",
              "123  waterbury vt email me on willing to anywhere a...  \n",
              "124  research and development scientist burlington ...  \n",
              "\n",
              "[125 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a139611a-e817-42ca-b3c0-cbc2f80997a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resume_id</th>\n",
              "      <th>class</th>\n",
              "      <th>resume_text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>lemmatized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>resume_1</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>\\rCustomer Service Supervisor/Tier - Isabella ...</td>\n",
              "      <td>customer service isabella catalog company sout...</td>\n",
              "      <td>customer service isabella catalog company sout...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>resume_2</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>\\rEngineer / Scientist - IBM Microelectronics ...</td>\n",
              "      <td>engineer scientist ibm microelectronics divisi...</td>\n",
              "      <td>engineer scientist ibm microelectronics divisi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>resume_3</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>\\rLTS Software Engineer Computational Lithogra...</td>\n",
              "      <td>lts software engineer computational lithograph...</td>\n",
              "      <td>lts software engineer computational lithograph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>resume_4</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>TUTOR\\rWilliston VT - Email me on Indeed: ind...</td>\n",
              "      <td>tutor williston vt email me on work experience...</td>\n",
              "      <td>tutor williston vt email me on work experience...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>resume_5</td>\n",
              "      <td>flagged</td>\n",
              "      <td>\\rIndependent Consultant - Self-employed\\rBurl...</td>\n",
              "      <td>independent consultant burlington vt email me ...</td>\n",
              "      <td>independent consultant burlington vt email me ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>resume_121</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>\\rBrattleboro VT - Email me on Indeed: indeed....</td>\n",
              "      <td>brattleboro vt email me on skilled presenter t...</td>\n",
              "      <td>brattleboro vt email me on skilled presenter t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>resume_122</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>\\rResearch and Teaching Assistant - University...</td>\n",
              "      <td>research and teaching assistant university of ...</td>\n",
              "      <td>research and teaching assistant university of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>resume_123</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>\\rMedical Coder - Highly Skilled - Entry Level...</td>\n",
              "      <td>medical coder highly skilled entry level sudbu...</td>\n",
              "      <td>medical coder highly skilled entry level sudbu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>resume_124</td>\n",
              "      <td>flagged</td>\n",
              "      <td>\\rWaterbury VT - Email me on Indeed: indeed.co...</td>\n",
              "      <td>waterbury vt email me on willing to anywhere a...</td>\n",
              "      <td>waterbury vt email me on willing to anywhere a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>resume_125</td>\n",
              "      <td>not_flagged</td>\n",
              "      <td>\\rResearch and Development Scientist - Burling...</td>\n",
              "      <td>research and development scientist burlington ...</td>\n",
              "      <td>research and development scientist burlington ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>125 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a139611a-e817-42ca-b3c0-cbc2f80997a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a139611a-e817-42ca-b3c0-cbc2f80997a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a139611a-e817-42ca-b3c0-cbc2f80997a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2969cb7-6e5c-4eb7-aae7-0f4fc0abd4af\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2969cb7-6e5c-4eb7-aae7-0f4fc0abd4af')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2969cb7-6e5c-4eb7-aae7-0f4fc0abd4af button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_271f84e3-6c02-4454-a4ad-8a012a70af7f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_271f84e3-6c02-4454-a4ad-8a012a70af7f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# # Download NLTK resources\n",
        "# # nltk.download('stopwords')\n",
        "# # nltk.download('wordnet')\n",
        "\n",
        "# # Load the dataset\n",
        "# df=pd.read_csv(r'/content/drive/MyDrive/Datasets/Sheet_2.csv',encoding='latin-1')\n",
        "\n",
        "# # Text cleaning and lemmatization functions\n",
        "# def clean_text(text):\n",
        "#     text = text.lower()\n",
        "#     text = ' '.join([word for word in text.split() if word.isalpha()])\n",
        "#     return text\n",
        "\n",
        "# def lemmatize_text(text):\n",
        "#     lemmatizer = WordNetLemmatizer()\n",
        "#     tokens = nltk.word_tokenize(text)\n",
        "#     lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "#     return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# # Apply text cleaning and lemmatization\n",
        "# df['cleaned_text'] = df['text'].apply(clean_text)\n",
        "# df['lemmatized_text'] = df['cleaned_text'].apply(lemmatize_text)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['lemmatized_text'], df['class'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "max_words = 5000\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "max_sequence_length = 100  # You can adjust this based on your data\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Build an RNN model\n",
        "embedding_dim = 50\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "LXhyMC2LA9X8"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12-Ewr74C5Qi",
        "outputId": "64a3694b-4f4e-4017-fe9f-b7c1e26bfebb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXsPghfgE6JR",
        "outputId": "8025ea83-b45b-4028-cad4-8e6f87c95772"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67           0\n",
              "12           0\n",
              "24     flagged\n",
              "45           0\n",
              "108          0\n",
              "        ...   \n",
              "106    flagged\n",
              "14           0\n",
              "92           0\n",
              "51           0\n",
              "102          0\n",
              "Name: class, Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ...\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "jD1KxPMkA9n0"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train_padded, y_train_encoded, epochs=50, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test_padded)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test_encoded, y_pred)\n",
        "classification_rep = classification_report(y_test_encoded, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{classification_rep}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC81eeFCHkAj",
        "outputId": "c36bb344-b608-4df4-f51d-d3cc7f47a88f"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 7.7190e-04 - accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 7.3194e-04 - accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 7.0083e-04 - accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 6.7175e-04 - accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 6.4298e-04 - accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 6.1512e-04 - accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 5.9052e-04 - accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 5.6427e-04 - accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 5.3872e-04 - accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 5.1655e-04 - accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 4.9546e-04 - accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 4.7699e-04 - accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 4.5849e-04 - accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 4.4203e-04 - accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 4.2643e-04 - accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 4.1179e-04 - accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 3.9720e-04 - accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 3.8330e-04 - accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 3.7003e-04 - accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 3.5845e-04 - accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 3.4587e-04 - accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 3.3477e-04 - accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 3.2511e-04 - accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 3.1534e-04 - accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 3.0627e-04 - accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 2.9784e-04 - accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 2.8943e-04 - accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 2.8113e-04 - accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 2.7357e-04 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.6611e-04 - accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.5924e-04 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.5264e-04 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 2.4651e-04 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 2.4042e-04 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 2.3482e-04 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 2.2927e-04 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 2.2385e-04 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 2.1820e-04 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.1302e-04 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.0757e-04 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 2.0259e-04 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.9802e-04 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 1.9363e-04 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 1.8936e-04 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 1.8541e-04 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 1.8147e-04 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 1.7760e-04 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 1.7399e-04 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 1.7047e-04 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 1.6716e-04 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Accuracy: 0.4\n",
            "Confusion Matrix:\n",
            "[[10  0]\n",
            " [15  0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      1.00      0.57        10\n",
            "           1       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.40        25\n",
            "   macro avg       0.20      0.50      0.29        25\n",
            "weighted avg       0.16      0.40      0.23        25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_ivCFd6IFc2",
        "outputId": "a24abc04-14ba-4f7b-8035-cf065653a97e"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.11.17)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameter\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['lemmatized_text'], df['class'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "max_words = 5000\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "max_sequence_length = 100  # You can adjust this based on your data\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Define the RNN model\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=max_words, output_dim=hp.Int('embedding_dim', min_value=32, max_value=128, step=32), input_length=max_sequence_length))\n",
        "    model.add(Bidirectional(LSTM(units=hp.Int('units', min_value=32, max_value=128, step=32), return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(units=hp.Int('units', min_value=32, max_value=128, step=32))))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model with the specified learning rate\n",
        "    model.compile(optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize the tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,  # You can increase this for more comprehensive search\n",
        "    directory='tuner',\n",
        "    project_name='rnn_hyperparameter_tuning'\n",
        ")\n",
        "\n",
        "# Perform hyperparameter search\n",
        "tuner.search(X_train_padded, y_train, epochs=5, validation_data=(X_test_padded, y_test))\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Build the final model with the best hyperparameters\n",
        "final_model = tuner.hypermodel.build(best_hps)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ...\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "final_model.fit(X_train_padded, y_train_encoded, epochs=10, validation_data=(X_test_padded, y_test_encoded))\n",
        "\n",
        "# Evaluate the final model\n",
        "eval_result = final_model.evaluate(X_test_padded, y_test)\n",
        "print(f\"Final Model - Test Accuracy: {eval_result[1]*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "jkRiJzwXNhEM",
        "outputId": "e807d10f-433b-4573-b2a1-4435eda59300"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f1373088d7be>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkerastuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuners\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkerastuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kerastuner'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: ok buid SVM model for same\\\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an SVM model\n",
        "model = SVC()\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{classification_rep}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "3i2RI7seA93F",
        "outputId": "9aed49f5-608b-4693-a4b6-2d713b5a3352"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-3df17f27cf1d>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Split the data into train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Create an SVM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN6hXMrHA-Gq",
        "outputId": "11ec274f-7c4c-4237-809c-2887956b7d89"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['lemmatized_text'], df['class'], test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Build an SVM model\n",
        "svm_model = SVC(kernel='linear')  # You can experiment with different kernels\n",
        "\n",
        "# Train the model\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = svm_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{classification_rep}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi-5n41-A-UM",
        "outputId": "1a8d00ac-34e8-464b-fde2-2aa8bbc39a7e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6\n",
            "Confusion Matrix:\n",
            "[[ 0 10]\n",
            " [ 0 15]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     flagged       0.00      0.00      0.00        10\n",
            " not_flagged       0.60      1.00      0.75        15\n",
            "\n",
            "    accuracy                           0.60        25\n",
            "   macro avg       0.30      0.50      0.37        25\n",
            "weighted avg       0.36      0.60      0.45        25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['lemmatized_text'], df['class'], test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Build an SVM model with hyperparameter optimization\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10,100],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "svm_model = SVC()\n",
        "grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Build the final model with the best parameters\n",
        "final_model = SVC(**best_params)\n",
        "final_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = final_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{classification_rep}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouhK4-4_A7q0",
        "outputId": "d238c010-5738-42b7-b877-e7444b09b035"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Accuracy: 0.68\n",
            "Confusion Matrix:\n",
            "[[ 3  7]\n",
            " [ 1 14]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     flagged       0.75      0.30      0.43        10\n",
            " not_flagged       0.67      0.93      0.78        15\n",
            "\n",
            "    accuracy                           0.68        25\n",
            "   macro avg       0.71      0.62      0.60        25\n",
            "weighted avg       0.70      0.68      0.64        25\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "Q1ZUAxYHuabM"
      }
    }
  ]
}